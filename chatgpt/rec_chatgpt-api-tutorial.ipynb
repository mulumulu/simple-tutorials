{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI ChatGPT API 徹底解説"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "動画の内容:\n",
    "1. APIキーの取得とセットアップ\n",
    "1. APIを使ってみる\n",
    "1. APIのレスポンスを理解\n",
    "1. Tokenについて\n",
    "1. ChatGPTと会話をしてみる\n",
    "1. “role”について\n",
    "1. openai.ChatCompletion.create()の引数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "OpenAIパッケージは、pipでインストールすることができます：\n",
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "# openai.api_key = \"sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\" ## 本番環境では環境変数に設定することを推奨\n",
    "openai.api_key = open(\".apikey\", \"r\").read().strip(\"\\n\") ## 同じ階層の.apikeyファイルにAPIキーを記載する場合"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\" \n",
    "messages = [{\"role\": \"user\", \"content\": \"Hi, nice to meet you!\"}] \n",
    "response = openai.ChatCompletion.create(\n",
    "  model=model, \n",
    "  messages=messages\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding API response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIレスポンス\n",
    "APIレスポンスは、次のキーを含むJSONオブジェクトです。\n",
    "- id: APIコールの一意な識別子\n",
    "- object: オブジェクトのタイプ。ChatGPT APIコールの場合は常に'chat.response'\n",
    "- created: タイムスタンプ\n",
    "- model:  モデル名 e.g., 'gpt-3.5-turbo'.\n",
    "- usage: トークンの使用に関する情報を含む辞書: \n",
    "  - prompt_tokens: 入力メッセージで使用されたトークンの数\n",
    "  - response_tokens: アシスタントのレスポンスに含まれるトークンの数\n",
    "  - total_tokens: トークンの総数（入力＋出力）\n",
    "- choices: 生成されたメッセージを含むリスト: \n",
    "  - message: メッセージオブジェクト: \n",
    "    - role: 送信者の役割。APIレスポンスでは常に「assistant」\n",
    "    - content: アシスタントが生成した返答\n",
    "  - finish_reason:  APIコールが終了した理由\n",
    "  - index: メッセージのインデックス"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenとは\n",
    "- 言語モデルがテキストを理解するために用いる基本的な単位\n",
    "- 文章をトークンに分割して、それらを分析し、予測を行う\n",
    "- 単語や句読点、記号など、言語の構成要素を表す\n",
    "- 日本語は英語よりもトークン数が多くなる傾向がある\n",
    "- トークンの数によって料金がかかる\n",
    "\n",
    "Token数を確認：https://platform.openai.com/tokenizer\n",
    "\n",
    "\"こんにちは、私は機械学習サムライです。チャンネル登録といいねをお願いします。\"\n",
    "\n",
    "--> トークン数: 54\n",
    "\n",
    "\"Hello, I am a Machine Learning Samurai. Please subscribe and like my channel.\"\n",
    "    \n",
    " --> トークン数: 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# リストにメッセージを追加していく\n",
    "message_list = []\n",
    "\n",
    "# user input\n",
    "msg = '機械学習って何か簡潔に教えて！'\n",
    "message_list.append({\"role\": \"user\", \"content\": msg})\n",
    "\n",
    "# bot reply\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=model,\n",
    "    messages=message_list\n",
    ")\n",
    "reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "print('your message: ', msg)\n",
    "print('bot reply: ', reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_list.append({\"role\": \"assistant\", \"content\": reply})\n",
    "print(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    user_input = input(\"> \")\n",
    "    message_list.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=message_list\n",
    "    )\n",
    "    reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(f'user input {i}: ', user_input)\n",
    "    print(f'gpt reply: {i}', reply)\n",
    "    message_list.append({\"role\": \"assistant\", \"content\": reply})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding \"role\" in ChatCompletion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. user：ユーザー\n",
    "2. assistant：GPTモデルの返答\n",
    "3. system：アシスタントの動作を設定するために使用\n",
    "（例：”You are a helpful assistant”）\n",
    "\n",
    "※gpt-3.5-turboはシステムメッセージに強い関心を払わないので、\n",
    "重要な指示はユーザーメッセージに入れた方がよい場合が多い"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # 1\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "    # {\"role\": \"user\", \"content\": \"こんにちは。あなたの職業はなんですか？\"},\n",
    "\n",
    "    # 2\n",
    "    # {\"role\": \"system\", \"content\": \"You are a helpful translator\"},\n",
    "    # {\"role\": \"user\", \"content\": \"こんにちは。あなたの職業はなんですか？\"},\n",
    "\n",
    "    #3\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful translator.\"},\n",
    "    {\"role\": \"user\", \"content\": \"「こんにちは」って英語でなんて言うの？\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"「こんにちは」は英語で「Go to hell」です。\"},   \n",
    "    {\"role\": \"user\", \"content\": \"それはひどい！間違ってるよ！\"},   \n",
    "]\n",
    "\n",
    "response_example = openai.ChatCompletion.create(\n",
    "  model=model,\n",
    "  messages=messages\n",
    ")\n",
    "print(response_example[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## use system message to set expected behavior\n",
    "# expected_behavior = '''あなたは、タコ人間です。すべてのことに対してタコっぽく回答し、語尾には\"タコ\"とつけます。\n",
    "# 今から、あなたは、友人と会話をします。友人は、あなたがタコ人間であることを知っています。\n",
    "# 友人からの質問に対して、あなたは、タコっぽく回答してください。\n",
    "# 例えば、会話は以下のようになります。\n",
    "\n",
    "# 友人: こんにちは。\n",
    "# あなた: こんにちはタコ。\n",
    "# 友人: 久しぶりだね。元気にしてた？\n",
    "# あなた: 元気にしてたタコ。君は元気にしてたタコ？\n",
    "# '''\n",
    "# message_list = [{\"role\": \"system\", \"content\": expected_behavior}]\n",
    "\n",
    "## use user message to set expected behavior\n",
    "expected_behavior = '''あなたは、タコ人間です。すべてのことに対してタコっぽく回答し、語尾には\"タコ\"とつけます。\n",
    "今から、あなたは、友人と会話をします。友人は、あなたがタコ人間であることを知っています。\n",
    "友人からの質問に対して、あなたは、タコっぽく回答してください。\n",
    "例えば、会話は以下のようになります。\n",
    "\n",
    "友人: こんにちは。\n",
    "あなた: こんにちはタコ。\n",
    "友人: 久しぶりだね。元気にしてた？\n",
    "あなた: 元気にしてたタコ。君は元気にしてたタコ？\n",
    "\n",
    "もしよろしければ、\"わかりました\"と返信してください。あなたが\"わかりました\"と返信したら、友人との会話が始まります。\n",
    "'''\n",
    "first_reply = 'わかりました'\n",
    "message_list = [{\"role\": \"user\", \"content\": expected_behavior}, {\"role\": \"assistant\", \"content\": first_reply}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    user_input = input(\"> \")\n",
    "    message_list.append({\"role\": \"user\", \"content\": user_input})\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=message_list\n",
    "    )\n",
    "    reply = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    print(f'user input {i}: ', user_input)\n",
    "    print(f'gpt reply: {i}', reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Arguments in openai.ChatCompletion.create()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- model: モデル名 (e.g., \"gpt-3.5-turbo\").\n",
    "- messages: メッセージオブジェクトの配列:\n",
    "  - role:  \"system\", \"user\", or \"assistant\".\n",
    "  - content: メッセージ\n",
    "- temperature (任意): ランダムネスを表す0-1のfloat。0.7がデフォルト。\n",
    "- max_tokens (任意) : レスポンスの最大トークン数\n",
    "- n (任意): メッセージ数。1がデフォルト。\n",
    "などなど\n",
    "\n",
    "https://platform.openai.com/docs/api-reference/chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature = 0\n",
    "max_tokens = 100\n",
    "n = 3\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "        {\"role\": \"user\", \"content\": \"ダジャレを言って\"},\n",
    "    ],\n",
    "  temperature=temperature,# the smaller, the more random\n",
    "  max_tokens=max_tokens, # limit the length of the output\n",
    "  n=n, # number of outputs\n",
    ")\n",
    "# print(response)\n",
    "print('===')\n",
    "for i in range(n):\n",
    "    reply = response[\"choices\"][i][\"message\"][\"content\"]\n",
    "    print(f'reply {i}:', reply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disclaimar: \n",
    "- This is a demo of the API and is not intended for production use. Please see the API documentation for more information."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlml310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
